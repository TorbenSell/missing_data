{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6511e7a",
   "metadata": {},
   "source": [
    "### Functions implemented \n",
    "\n",
    "A complete case k-nearest neighbour classifier, returns an estimated label for the test point:\n",
    "```python\n",
    "def complete_case_kNN_classifier(x_test, X_train, Y_train, O_train)\n",
    "```\n",
    "\n",
    "Two imputation methods can be called, both require only the training data and the observations patterns thereof as inputs, they return an imputed data set of the same size as X_train. The first one imputes with a constant (default is $0$ unless specified otherwise by the user), the second one with the mean of all observed variables.\n",
    "```python\n",
    "def constant_impute(X_train, O_train, c=0)\n",
    "def mean_impute(X_train, O_train)\n",
    "```\n",
    "\n",
    "The HAM classifier is implemented, which is given an estimate $\\hat{\\Omega}$ of (or the true) $\\Omega^\\star$, and returns an estimated label of the test point. An estimate $\\hat{\\Omega}$ can be obtained from the training data using the second function:\n",
    "```python\n",
    "def HAM_classifier(x_test, Omega_hat, X_train, Y_train, O_train)\n",
    "def estimate_Omega_star(X_train, Y_train, O_train)\n",
    "```\n",
    "\n",
    "The HAM classifier make use of three auxiliary functions:\n",
    "```python\n",
    "def transform_j_to_omega(j_omega, d)\n",
    "def transform_omega_to_j(omega, d)\n",
    "def all_obs_patterns_of_length(d)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d12774a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-10T21:02:40.986460Z",
     "iopub.status.busy": "2023-05-10T21:02:40.984906Z",
     "iopub.status.idle": "2023-05-10T21:02:43.098789Z",
     "shell.execute_reply": "2023-05-10T21:02:43.099242Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "d = 5\n",
    "beta = 1\n",
    "alpha = 1\n",
    "gamma = np.ones(2**d)\n",
    "gamma_max = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6238303",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-10T21:02:43.107368Z",
     "iopub.status.busy": "2023-05-10T21:02:43.106767Z",
     "iopub.status.idle": "2023-05-10T21:02:43.108908Z",
     "shell.execute_reply": "2023-05-10T21:02:43.109370Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "complete case k-nearest neighbour classifier\n",
    "\"\"\"\n",
    "        \n",
    "        \n",
    "''' Predict value of test point using all available cases '''\n",
    "def complete_case_kNN_classifier(x_test, X_train, Y_train, O_train):\n",
    "    mc_distances = []\n",
    "    mc_y = []\n",
    "    no_matching_cases = 0\n",
    "    \n",
    "    for i in range(N_train):\n",
    "        if np.all(np.ones(d)<=O_train[i,:]):\n",
    "            no_matching_cases += 1\n",
    "            dist = 0\n",
    "            for j in range(d):\n",
    "                dist += (x_test[j]-X_train[i,j])**2\n",
    "            mc_distances.append(np.sqrt(dist))\n",
    "            mc_y.append(Y_train[i])\n",
    "            \n",
    "    sort_index = np.argsort(mc_distances)\n",
    "    k_mc = int(np.rint(1/3 * no_matching_cases**(beta*gamma_max*(1+alpha)/(gamma_max*(2*beta+d)+alpha*beta))))\n",
    "    \n",
    "    if no_matching_cases==0:\n",
    "        if np.random.uniform()<1/2:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    else:\n",
    "        eta_sum = 0\n",
    "        for i in range(k_mc):\n",
    "            eta_sum += 1/k_mc * mc_y[sort_index[i]]\n",
    "\n",
    "        if eta_sum<1/2:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0c4dbf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-10T21:02:43.115319Z",
     "iopub.status.busy": "2023-05-10T21:02:43.114713Z",
     "iopub.status.idle": "2023-05-10T21:02:43.116758Z",
     "shell.execute_reply": "2023-05-10T21:02:43.117156Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Imputation methods\n",
    "\"\"\"\n",
    "\n",
    "def constant_impute(X_train, O_train, c=0):\n",
    "    X_imputed = np.zeros((N_train,d))\n",
    "    X_imputed += X_train\n",
    "    if c!=0:\n",
    "        for it in range(N_train):\n",
    "            for i in range(d):\n",
    "                if O_train[it,i]==0:\n",
    "                    X_imputed[it,i] = c\n",
    "    return X_imputed\n",
    "\n",
    "def mean_impute(X_train, O_train):\n",
    "    X_imputed = np.zeros((N_train,d))\n",
    "    X_imputed += X_train\n",
    "    \n",
    "    means = np.zeros(d)\n",
    "    for i in range(d):\n",
    "        means[i] = np.sum(X_train[:,i])/np.sum(O_train[:,i])\n",
    "    \n",
    "    for it in range(N_train):\n",
    "        for i in range(d):\n",
    "            if O_train[it,i]==0:\n",
    "                X_imputed[it,i] = means[i]\n",
    "    return X_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfb71ada",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-10T21:02:43.128243Z",
     "iopub.status.busy": "2023-05-10T21:02:43.127218Z",
     "iopub.status.idle": "2023-05-10T21:02:43.130644Z",
     "shell.execute_reply": "2023-05-10T21:02:43.131091Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[array([0, 0, 0])], [array([0, 0, 1]), array([0, 1, 0]), array([1, 0, 0])], [array([0, 1, 1]), array([1, 0, 1]), array([1, 1, 0])], [array([1, 1, 1])]]\n",
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "NB: (0,1,0,0,1,0,1) will be the 0100101_2-th = 37_10-th entry. Can transform by taking \n",
    "omega = (omega_1,...,omega_d-1,omega_d) --> corresponding j=omega_d+2*omega_d-1+4*omega_d-2+...+2^(d-1)*omega_1\n",
    "and also in the other direction\n",
    "omega_d = j mod2, omega_d-1=((j-omega_d)/2) mod2, omega_d-2 = ((j-omega_d-omega_d-2)/4) mod2, et cetera.\n",
    "This is implemented in the next two functions.\n",
    "\"\"\"\n",
    "def transform_j_to_omega(j_omega, d):\n",
    "    omega=np.zeros(d,dtype=\"int\")\n",
    "    j=0\n",
    "    j+=j_omega\n",
    "    \n",
    "    for k in range(d):\n",
    "        omega[d-1-k]=j%2\n",
    "        j=(j-omega[d-1-k])/2\n",
    "    return omega\n",
    "\n",
    "def transform_omega_to_j(omega, d):\n",
    "    j=0\n",
    "    for k in range(d):\n",
    "        j+=omega[d-1-k]*(2**k)\n",
    "    return j \n",
    "\n",
    "\n",
    "''' To create a list with all possible observation patterns we firstly define the following functions '''\n",
    "def all_obs_patterns_of_length(d):\n",
    "    pattern_list = []\n",
    "    omega=np.zeros(d,dtype=\"int\")\n",
    "\n",
    "    for k in range(d+1):\n",
    "        pattern_list.append([])\n",
    "        \n",
    "    for j in range(2**d):\n",
    "        omega = transform_j_to_omega(j,d)\n",
    "        o = int(np.sum(omega))\n",
    "        pattern_list[o].append(omega)\n",
    "        \n",
    "    return pattern_list\n",
    "\n",
    "    \n",
    "\"\"\" Create a list with all possible observation patterns of length l with o observations (as np arrays), sorted by the number of observed values \"\"\"\n",
    "obs_patterns_with_o_observations_and_length_d = []\n",
    "obs_patterns_with_o_observations_and_length_d.append([])\n",
    "for l in range(1,d+1):\n",
    "    obs_patterns_with_o_observations_and_length_d.append(all_obs_patterns_of_length(l))\n",
    "\n",
    "\"\"\" Check that these are the correct observations patterns \"\"\"    \n",
    "print(obs_patterns_with_o_observations_and_length_d[3])\n",
    "print(obs_patterns_with_o_observations_and_length_d[2][1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa445d09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-10T21:02:43.144171Z",
     "iopub.status.busy": "2023-05-10T21:02:43.143554Z",
     "iopub.status.idle": "2023-05-10T21:02:43.145608Z",
     "shell.execute_reply": "2023-05-10T21:02:43.146071Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "HAM Classifier\n",
    "\"\"\"\n",
    "\n",
    "''' Predict value of fully observed test point using missing data anova decomposition '''\n",
    "def HAM_classifier(x_test, Omega_hat, X_train, Y_train, O_train):\n",
    "    \n",
    "    # f_0 is the expectation of Y-1/2\n",
    "    f_hat_0 = sum(Y_train)/len(Y_train) - 1/2\n",
    "    \n",
    "    \"\"\" Estimate f_omega at test point for each observation pattern \"\"\"   \n",
    "    f_hat_omega = np.zeros(2**d)\n",
    "    f_hat_omega[0] = f_hat_0 \n",
    "    \n",
    "    ''' Iterate through the different observation patterns '''\n",
    "    for o in range(1,d+1):\n",
    "        l_max = len(obs_patterns_with_o_observations_and_length_d[d][o])\n",
    "        for omega_d_o in range(l_max):\n",
    "            \n",
    "            # get observation pattern, transform to index\n",
    "            omega = obs_patterns_with_o_observations_and_length_d[d][o][omega_d_o]\n",
    "            j_omega = transform_omega_to_j(omega,d)\n",
    "            \n",
    "            # calculate number of available cases\n",
    "            N_available = 0\n",
    "            for it in range(N_train):\n",
    "                if (omega<=O_train[it,:]).all():\n",
    "                    N_available += 1\n",
    "            \n",
    "            # calculate \n",
    "            if N_available>0:\n",
    "                gamma_omega = 1#np.amax(gamma*omega)\n",
    "                exponent = beta*gamma_omega/(gamma_omega*(2*beta+sum(omega))+alpha*beta)\n",
    "                k_omega = 1+int(np.floor(N_available**(2*exponent)))\n",
    "                        \n",
    "            # Estimate f_omega at test point\n",
    "            if N_available>=1:\n",
    "\n",
    "                # compute distances to test point, only considering the w-observed variables\n",
    "                distances = []\n",
    "                for i in range(N_train):\n",
    "                    if (omega<=O_train[i,:]).all():\n",
    "                        dist = 0\n",
    "                        for k in range(d):\n",
    "                            if omega[k]==1:\n",
    "                                dist += (x_test[k]-X_train[i,k])**2\n",
    "                        distances.append(np.sqrt(dist))\n",
    "                    else:\n",
    "                        distances.append(100.0) # make sure that unavailable data points are not a nearest neighbour\n",
    "\n",
    "                # sort distances\n",
    "                sort_index = np.argsort(distances)\n",
    "\n",
    "                # add Monte Carlo estimate of eta to f_omega\n",
    "                for i in range(k_omega):\n",
    "                    f_hat_omega[j_omega] += 1/k_omega * Y_train[sort_index[i]] \n",
    "\n",
    "                # substract 1/2 from the estimate\n",
    "                f_hat_omega[j_omega] -= 1/2\n",
    "\n",
    "                # substract Monte Carlo estimates of f_{omega_subset} from f_omega\n",
    "                omega_subset = np.zeros(d,dtype=\"int\")\n",
    "                for j_short in range(2**o-1):\n",
    "                    omega_short = transform_j_to_omega(j_short,o)\n",
    "                    omega_subset = 0*omega_subset\n",
    "                    omega_subset[np.nonzero(omega)] = omega_short\n",
    "                    j_subset = transform_omega_to_j(omega_subset,d)\n",
    "\n",
    "                    f_hat_omega[j_omega] -= f_hat_omega[j_subset]\n",
    "  \n",
    "        \n",
    "    ''' Estimate eta '''\n",
    "    eta_test = 1/2\n",
    "    for o in range(d+1):\n",
    "        l_max = len(obs_patterns_with_o_observations_and_length_d[d][o])\n",
    "        for omega_d_o in range(l_max):\n",
    "            \n",
    "            # get observation pattern, transform to index\n",
    "            omega = obs_patterns_with_o_observations_and_length_d[d][o][omega_d_o]\n",
    "            j_omega = transform_omega_to_j(omega,d)\n",
    "            \n",
    "            # check if omega<= element for some element in Omega_hat, return 1 if this is the case\n",
    "            helpy = 0 \n",
    "            for elem in Omega_hat:\n",
    "                if (omega<=elem).all():\n",
    "                    helpy = 1\n",
    "                    \n",
    "            # if intersection is empty, add omega to Omega_hat\n",
    "            if helpy == 1:\n",
    "                eta_test += f_hat_omega[j_omega]\n",
    "                            \n",
    "    if eta_test<1/2:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a390711b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-10T21:02:43.160950Z",
     "iopub.status.busy": "2023-05-10T21:02:43.159872Z",
     "iopub.status.idle": "2023-05-10T21:02:43.162165Z",
     "shell.execute_reply": "2023-05-10T21:02:43.162542Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "HAM Classifier - estimates Omega hat and then uses the oracle version\n",
    "\"\"\"\n",
    "\n",
    "''' Estimate Omega_star using missing data anova decomposition '''\n",
    "def estimate_Omega_star(X_train, Y_train, O_train):\n",
    "    \n",
    "    # Quantities needed for thresholding\n",
    "    tau_omega = np.ones(2**d)\n",
    "    sigma_hat_omega_sq = np.zeros(2**d)\n",
    "    \n",
    "    # f_0 is the expectation of Y-1/2\n",
    "    f_hat_0 = sum(Y_train)/len(Y_train) - 1/2\n",
    "    sigma_hat_omega_sq[0] = f_hat_0**2\n",
    "    \n",
    "    \"\"\" Estimate f_omega at all training points for each observation pattern \"\"\"   \n",
    "    f_hat_omega = np.zeros((N_train,2**d))\n",
    "    f_hat_omega[:,0] = f_hat_0*np.ones(N_train) \n",
    "    \n",
    "    ''' Iterate through the different observation patterns '''\n",
    "    for o in range(1,d+1):\n",
    "        l_max = len(obs_patterns_with_o_observations_and_length_d[d][o])\n",
    "        for omega_d_o in range(l_max):\n",
    "            \n",
    "            # get observation pattern, transform to index\n",
    "            omega = obs_patterns_with_o_observations_and_length_d[d][o][omega_d_o]\n",
    "            j_omega = transform_omega_to_j(omega,d)\n",
    "            \n",
    "            # calculate number of available cases\n",
    "            N_available = 0\n",
    "            for it in range(N_train):\n",
    "                if (omega<=O_train[it,:]).all():\n",
    "                    N_available += 1\n",
    "            \n",
    "            # calculate \n",
    "            if N_available>0:\n",
    "                gamma_omega = 1#np.amax(gamma*omega)\n",
    "                exponent = beta*gamma_omega/(gamma_omega*(2*beta+sum(omega))+alpha*beta)\n",
    "                k_omega = 1+int(np.floor(N_available**(2*exponent)))\n",
    "                tau_omega[j_omega] = 1/(N_available**exponent)/16\n",
    "            \n",
    "            # For all training points that are available cases for the observation pattern\n",
    "            for it in range(N_train):\n",
    "                if (omega<=O_train[it,:]).all() and N_available>=1:\n",
    "            \n",
    "                    # compute distances to all other training points, only considering the w-observed variables\n",
    "                    distances = []\n",
    "                    for i in range(N_train):\n",
    "                        if (omega<=O_train[i,:]).all():\n",
    "                            dist = 0\n",
    "                            for k in range(d):\n",
    "                                if omega[k]==1:\n",
    "                                    dist += (X_train[it,k]-X_train[i,k])**2\n",
    "                            distances.append(np.sqrt(dist))\n",
    "                        else:\n",
    "                            distances.append(1000) # make sure that unavailable data points are not a nearest neighbour\n",
    "\n",
    "                    # sort distances and decide on k_omega and the threshold tau_omega\n",
    "                    sort_index = np.argsort(distances)\n",
    "\n",
    "                    # add Monte Carlo estimate of eta to f_omega\n",
    "                    for i in range(k_omega):\n",
    "                        f_hat_omega[it,j_omega] += 1/k_omega * Y_train[sort_index[i]] \n",
    "\n",
    "                    # substract 1/2 from the estimate\n",
    "                    f_hat_omega[it,j_omega] -= 1/2\n",
    "\n",
    "                    # substract Monte Carlo estimates of f_{omega_subset} from f_omega\n",
    "                    omega_subset = np.zeros(d,dtype=\"int\")\n",
    "                    for j_short in range(2**o-1):\n",
    "                        omega_short = transform_j_to_omega(j_short,o)\n",
    "                        omega_subset = 0*omega_subset\n",
    "                        omega_subset[np.nonzero(omega)] = omega_short\n",
    "                        j_subset = transform_omega_to_j(omega_subset,d)\n",
    "\n",
    "                        f_hat_omega[it,j_omega] -= f_hat_omega[it,j_subset]\n",
    "                    \n",
    "            # Calculate Sobol index                   \n",
    "            if N_available>=1:\n",
    "                sigma_hat_omega_sq[j_omega] = 1/N_available * np.sum(f_hat_omega[0:N_train,j_omega]**2)     \n",
    "\n",
    "    \"\"\" Estimate Omega_hat \"\"\"                        \n",
    "    Omega_hat = []\n",
    "    Omega_hat_cup_L_Omega_hat = []\n",
    "    \n",
    "    ''' Iterate through the different observation patterns, starting from the fully observed one '''\n",
    "    for d_prime in range(d+1):\n",
    "        \n",
    "        l_max = len(obs_patterns_with_o_observations_and_length_d[d][d-d_prime])\n",
    "        for omega_d_d_prime in range(l_max):\n",
    "            \n",
    "            # get observation pattern, transform to index\n",
    "            omega = obs_patterns_with_o_observations_and_length_d[d][d-d_prime][omega_d_d_prime]\n",
    "            \n",
    "            # check if U({omega}) intersect hat_Omega is empty, return 0 if this is the case\n",
    "            helpy = 0 \n",
    "            for elem in Omega_hat_cup_L_Omega_hat:\n",
    "                if (elem==omega).all():\n",
    "                    helpy = 1\n",
    "                    \n",
    "            # if intersection is empty, add omega to Omega_hat and L(omega) to Omega_hat_cup_L_Omega_hat\n",
    "            if helpy == 0:\n",
    "                j_omega = transform_omega_to_j(omega,d)\n",
    "                if sigma_hat_omega_sq[j_omega] >= tau_omega[j_omega]:\n",
    "                    Omega_hat.append(omega)\n",
    "                    omega_subset = np.zeros(d,dtype=\"int\")\n",
    "                    for j_short in range(2**(d-d_prime)):\n",
    "                        omega_short = transform_j_to_omega(j_short,d-d_prime)\n",
    "                        omega_subset = 0*omega_subset\n",
    "                        omega_subset[np.nonzero(omega)] = omega_short\n",
    "                        Omega_hat_cup_L_Omega_hat.append(omega_subset)\n",
    "        \n",
    "    return Omega_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404be9d6",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dbcf53e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-10T21:02:43.166821Z",
     "iopub.status.busy": "2023-05-10T21:02:43.166246Z",
     "iopub.status.idle": "2023-05-10T21:02:43.169165Z",
     "shell.execute_reply": "2023-05-10T21:02:43.169620Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayes risk =  0.0787\n"
     ]
    }
   ],
   "source": [
    "all_accuracies_cc_kNN = np.zeros((2,100))\n",
    "all_accuracies_mi_kNN = np.zeros((2,100))\n",
    "all_accuracies_ci_kNN = np.zeros((2,100))\n",
    "all_accuracies_oracle_HAM = np.zeros((2,100))\n",
    "all_accuracies_HAM = np.zeros((2,100))\n",
    "\n",
    "\n",
    "''' Set Constants '''\n",
    "iterations = 100 # number of iterations for estimating the empirical test error\n",
    "N_test = 1000\n",
    "\n",
    "d = 2 # dimension of X, number of variables\n",
    "alpha = 1\n",
    "beta = 1\n",
    "gamma = np.ones(d)\n",
    "gamma_max = np.amax(gamma)\n",
    "\n",
    "u = np.array([np.sqrt(2),0],dtype=\"float\")\n",
    "Sigma = np.eye(d)\n",
    "Sigma_inv = np.linalg.inv(Sigma)\n",
    "w = -np.dot(Sigma_inv,u)\n",
    "\n",
    "p_MCAR = 0.7 # homogeneous MCAR observation probability\n",
    "\n",
    "\n",
    "def eta(x):\n",
    "    return np.exp(np.dot(x,w))/(np.exp(np.dot(x,w))+np.exp(-np.dot(x,w)))\n",
    "\n",
    "Bayes_risk = 0\n",
    "mean_point = np.zeros(d)\n",
    "x_point = np.zeros(d)\n",
    "for _ in range(1000000):\n",
    "    y_point = np.random.randint(2)\n",
    "    mean_point = ((-1)**y_point)*u\n",
    "    x_point = np.random.multivariate_normal(mean_point,Sigma)\n",
    "    eta_point = eta(x_point)\n",
    "    Bayes_risk += min(eta_point,1-eta_point)\n",
    "Bayes_risk = Bayes_risk/1000000\n",
    "print('Bayes risk = ', np.round(Bayes_risk,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "195420c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-10T21:36:16.257629Z",
     "iopub.status.busy": "2023-05-10T21:36:16.255359Z",
     "iopub.status.idle": "2023-05-10T22:43:03.634346Z",
     "shell.execute_reply": "2023-05-10T22:43:03.634783Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime Complete Case kNN (in s):  5.705\n",
      "    Accuracy:  0.901\n",
      "Runtime Mean Imputation and kNN (in s):  7.577\n",
      "    Accuracy:  0.903\n",
      "Runtime Constant Imputation and kNN (in s):  7.985\n",
      "    Accuracy:  0.904\n",
      "Runtime Oracle HAM (in s):  13.443\n",
      "    Accuracy:  0.918\n",
      "Runtime HAM (in s):  15.955\n",
      "    Accuracy:  0.918\n",
      "\n",
      "Estimated runtime (in min):  84.442\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-2320cc838b31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0mOmega_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimate_Omega_star\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mO_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mHAM_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOmega_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mO_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m             \u001b[0maccuracy_HAM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mN_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-560c869b17f6>\u001b[0m in \u001b[0;36mHAM_classifier\u001b[0;34m(x_test, Omega_hat, X_train, Y_train, O_train)\u001b[0m\n\u001b[1;32m     44\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0momega\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                                 \u001b[0mdist\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m                         \u001b[0mdistances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "EXAMPLE 1 - MCAR\n",
    "'''\n",
    "\n",
    "N_train = 500 \n",
    "\n",
    "\n",
    "''' \n",
    "Create 1 training and test point set, show runtime and calculate expected run time for simulation \n",
    "'''\n",
    "# Generate Training Data \n",
    "X_train = np.zeros((N_train,d))   # N_train data points\n",
    "Y_train = np.zeros(N_train)\n",
    "for i in range(N_train):\n",
    "    Y_train[i] = np.random.randint(2)   # Y=1 if signs of x[0] and x[1] are different, Y=0 otherwise\n",
    "    X_train[i] = np.random.multivariate_normal(((-1)**Y_train[i])*u,Sigma)   # normal distribution on [-1,1]^d, \n",
    "O_train = np.random.choice(2,size=(N_train,d),p=(1-p_MCAR,p_MCAR))\n",
    "\n",
    "# Generate Test Points\n",
    "x_test = np.zeros((N_test,d))\n",
    "y_test = np.zeros(N_test)\n",
    "for i in range(N_test):\n",
    "    y_test[i] = np.random.randint(2)\n",
    "    x_test[i,:] = np.random.multivariate_normal(((-1)**y_test[i])*u,Sigma) \n",
    "\n",
    "\n",
    "# Complete Case kNN\n",
    "start = time.time()\n",
    "accuracy_cc_kNN = 0\n",
    "for i in range(N_test):\n",
    "    if y_test[i] == complete_case_kNN_classifier(x_test[i,:],X_train,Y_train,O_train):\n",
    "        accuracy_cc_kNN += 1/N_test\n",
    "end = time.time()\n",
    "run_time_cc_kNN = end-start\n",
    "print('Runtime Complete Case kNN (in s): ',np.round(run_time_cc_kNN,3))\n",
    "print('    Accuracy: ',np.round(accuracy_cc_kNN,3))\n",
    "    \n",
    "# Mean Imputation then kNN\n",
    "start = time.time()\n",
    "X_imputed = mean_impute(X_train, O_train)\n",
    "accuracy_mi_kNN = 0\n",
    "for i in range(N_test):\n",
    "    if y_test[i] == complete_case_kNN_classifier(x_test[i,:],X_imputed,Y_train,np.ones((N_train,d))):\n",
    "        accuracy_mi_kNN += 1/N_test\n",
    "end = time.time()\n",
    "run_time_mi_kNN = end-start\n",
    "print('Runtime Mean Imputation and kNN (in s): ',np.round(run_time_mi_kNN,3))\n",
    "print('    Accuracy: ',np.round(accuracy_mi_kNN,3))\n",
    "\n",
    "# c=0 Imputation then kNN\n",
    "start = time.time()\n",
    "X_imputed = constant_impute(X_train, O_train)\n",
    "accuracy_ci_kNN = 0\n",
    "for i in range(N_test):\n",
    "    if y_test[i] == complete_case_kNN_classifier(x_test[i,:],X_imputed,Y_train,np.ones((N_train,d))):\n",
    "        accuracy_ci_kNN += 1/N_test\n",
    "end = time.time()\n",
    "run_time_ci_kNN = end-start\n",
    "print('Runtime Constant Imputation and kNN (in s): ',np.round(run_time_ci_kNN,3))\n",
    "print('    Accuracy: ',np.round(accuracy_ci_kNN,3))\n",
    "\n",
    "# Oracle HAM\n",
    "start = time.time()\n",
    "Omega_star = []\n",
    "Omega_star.append(np.array([1,0],dtype=\"int\"))\n",
    "accuracy_oracle_HAM = 0\n",
    "for i in range(N_test):\n",
    "    if y_test[i] == HAM_classifier(x_test[i,:], Omega_star, X_train, Y_train, O_train):\n",
    "        accuracy_oracle_HAM += 1/N_test\n",
    "end = time.time()\n",
    "run_time_oracle_HAM = end-start\n",
    "print('Runtime Oracle HAM (in s): ',np.round(run_time_oracle_HAM,3))\n",
    "print('    Accuracy: ',np.round(accuracy_oracle_HAM,3))\n",
    "\n",
    "# Adaptive HAM\n",
    "start = time.time()\n",
    "Omega_hat = []\n",
    "Omega_hat = estimate_Omega_star(X_train, Y_train, O_train)\n",
    "accuracy_HAM = 0\n",
    "for i in range(N_test):\n",
    "    if y_test[i] == HAM_classifier(x_test[i,:], Omega_hat, X_train, Y_train, O_train):\n",
    "        accuracy_HAM += 1/N_test\n",
    "end = time.time()\n",
    "run_time_HAM = end-start\n",
    "print('Runtime HAM (in s): ',np.round(run_time_HAM,3))\n",
    "print('    Accuracy: ',np.round(accuracy_HAM,3))\n",
    "\n",
    "\n",
    "print('\\nEstimated runtime (in min): ',np.round(iterations*(run_time_ci_kNN+run_time_cc_kNN+run_time_mi_kNN+run_time_HAM+run_time_oracle_HAM)/60,3))\n",
    "\n",
    "\n",
    "''' \n",
    "Create training and test point sets, estimate empirical test error\n",
    "'''\n",
    "accuracy_cc_kNN = np.zeros(iterations)\n",
    "accuracy_mi_kNN = np.zeros(iterations)\n",
    "accuracy_ci_kNN = np.zeros(iterations)\n",
    "accuracy_oracle_HAM = np.zeros(iterations)\n",
    "accuracy_HAM = np.zeros(iterations)\n",
    "\n",
    "for it in range(iterations):\n",
    "    \n",
    "    # Generate Training Data \n",
    "    X_train = np.zeros((N_train,d))   # N_train data points\n",
    "    Y_train = np.zeros(N_train)\n",
    "    for i in range(N_train):\n",
    "        Y_train[i] = np.random.randint(2)   # Y=1 if signs of x[0] and x[1] are different, Y=0 otherwise\n",
    "        X_train[i] = np.random.multivariate_normal(((-1)**Y_train[i])*u,Sigma)   # normal distribution on [-1,1]^d, \n",
    "    O_train = np.random.choice(2,size=(N_train,d),p=(1-p_MCAR,p_MCAR))\n",
    "\n",
    "    # Generate Test Points\n",
    "    x_test = np.zeros((N_test,d))\n",
    "    y_test = np.zeros(N_test)\n",
    "    for i in range(N_test):\n",
    "        y_test[i] = np.random.randint(2)\n",
    "        x_test[i,:] = np.random.multivariate_normal(((-1)**y_test[i])*u,Sigma) \n",
    "        \n",
    "    ''' Estimate Test Errors ''' \n",
    "    # Complete Case kNN\n",
    "    for i in range(N_test):\n",
    "        if y_test[i] == complete_case_kNN_classifier(x_test[i,:],X_train,Y_train,O_train):\n",
    "            accuracy_cc_kNN[it] += 1/N_test\n",
    "\n",
    "    # Mean Imputation then kNN  \n",
    "    for i in range(N_test):\n",
    "        X_imputed = mean_impute(X_train, O_train)\n",
    "        if y_test[i] == complete_case_kNN_classifier(x_test[i,:],X_imputed,Y_train,np.ones((N_train,d))):\n",
    "            accuracy_mi_kNN[it] += 1/N_test\n",
    "\n",
    "    # c=0 Imputation then kNN\n",
    "    for i in range(N_test):\n",
    "        X_imputed = constant_impute(X_train, O_train)\n",
    "        if y_test[i] == complete_case_kNN_classifier(x_test[i,:],X_imputed,Y_train,np.ones((N_train,d))):\n",
    "            accuracy_ci_kNN[it] += 1/N_test\n",
    "\n",
    "    # Oracle HAM\n",
    "    for i in range(N_test):\n",
    "        if y_test[i] == HAM_classifier(x_test[i,:], Omega_star, X_train, Y_train, O_train):\n",
    "            accuracy_oracle_HAM[it] += 1/N_test\n",
    "\n",
    "    # HAM\n",
    "    Omega_hat = []\n",
    "    Omega_hat = estimate_Omega_star(X_train, Y_train, O_train)\n",
    "    for i in range(N_test):\n",
    "        if y_test[i] == HAM_classifier(x_test[i,:], Omega_hat, X_train, Y_train, O_train):\n",
    "            accuracy_HAM[it] += 1/N_test\n",
    "    \n",
    "\n",
    "all_accuracies_cc_kNN[0,:] = accuracy_cc_kNN[0:100]\n",
    "all_accuracies_mi_kNN[0,:] = accuracy_mi_kNN[0:100]\n",
    "all_accuracies_ci_kNN[0,:] = accuracy_ci_kNN[0:100]\n",
    "all_accuracies_oracle_HAM[0,:] = accuracy_oracle_HAM[0:100]\n",
    "all_accuracies_HAM[0,:] = accuracy_HAM[0:100]\n",
    "    \n",
    "print('\\n\\nTest Accuracy Complete Case kNN: ',np.round(np.sum(accuracy_cc_kNN)/iterations,4))\n",
    "print('Test Accuracy Mean Imputation then kNN  : ',np.round(np.sum(accuracy_mi_kNN)/iterations,4))\n",
    "print('Test Accuracy c=0 Imputation then kNN: ',np.round(np.sum(accuracy_ci_kNN)/iterations,4))\n",
    "print('Test Accuracy Oracle HAM: ',np.round(np.sum(accuracy_oracle_HAM)/iterations,4))\n",
    "print('Test Accuracy HAM: ',np.round(np.sum(accuracy_HAM)/iterations,4))\n",
    "\n",
    "summary_accuracies = [accuracy_cc_kNN,accuracy_mi_kNN,accuracy_ci_kNN,accuracy_oracle_HAM,accuracy_HAM]\n",
    "summary_plot = sns.violinplot(summary_accuracies)\n",
    "\n",
    "summary_plot.set_xticklabels(['CC','MI kNN','CI kNN','oracle HAM','HAM'])\n",
    "\n",
    "plt.show(summary_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59afe783",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-10T22:43:03.662433Z",
     "iopub.status.busy": "2023-05-10T22:43:03.661121Z",
     "iopub.status.idle": "2023-05-11T01:02:09.843891Z",
     "shell.execute_reply": "2023-05-11T01:02:09.844332Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime Complete Case kNN (in s):  11.988\n",
      "    Accuracy:  0.897\n",
      "Runtime Mean Imputation and kNN (in s):  13.636\n",
      "    Accuracy:  0.894\n",
      "Runtime Constant Imputation and kNN (in s):  14.727\n",
      "    Accuracy:  0.901\n",
      "Runtime Oracle HAM (in s):  22.81\n",
      "    Accuracy:  0.906\n",
      "Runtime HAM (in s):  35.919\n",
      "    Accuracy:  0.906\n",
      "\n",
      "Estimated runtime (in min):  165.133\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-857508eacd4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;31m# Complete Case kNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcomplete_case_kNN_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mO_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0maccuracy_cc_kNN\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mN_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-187be6548f49>\u001b[0m in \u001b[0;36mcomplete_case_kNN_classifier\u001b[0;34m(x_test, X_train, Y_train, O_train)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0mO_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mno_matching_cases\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mall\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/MissData/lib/python3.9/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mall\u001b[0;34m(a, axis, out, keepdims, where)\u001b[0m\n\u001b[1;32m   2436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2437\u001b[0m     \"\"\"\n\u001b[0;32m-> 2438\u001b[0;31m     return _wrapreduction(a, np.logical_and, 'all', axis, None, out,\n\u001b[0m\u001b[1;32m   2439\u001b[0m                           keepdims=keepdims, where=where)\n\u001b[1;32m   2440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/MissData/lib/python3.9/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "EXAMPLE 1 - MCAR\n",
    "'''\n",
    "\n",
    "N_train = 1000 # number of training points\n",
    "\n",
    "\n",
    "''' \n",
    "Create 1 training and test point set, show runtime and calculate expected run time for simulation \n",
    "'''\n",
    "# Generate Training Data \n",
    "X_train = np.zeros((N_train,d))  \n",
    "Y_train = np.zeros(N_train)\n",
    "for i in range(N_train):\n",
    "    Y_train[i] = np.random.randint(2)   \n",
    "    X_train[i] = np.random.multivariate_normal(((-1)**Y_train[i])*u,Sigma)   \n",
    "O_train = np.random.choice(2,size=(N_train,d),p=(1-p_MCAR,p_MCAR))\n",
    "\n",
    "# Generate Test Points\n",
    "x_test = np.zeros((N_test,d))\n",
    "y_test = np.zeros(N_test)\n",
    "for i in range(N_test):\n",
    "    y_test[i] = np.random.randint(2)\n",
    "    x_test[i,:] = np.random.multivariate_normal(((-1)**y_test[i])*u,Sigma) \n",
    "\n",
    "# Complete Case kNN\n",
    "start = time.time()\n",
    "accuracy_cc_kNN = 0\n",
    "for i in range(N_test):\n",
    "    if y_test[i] == complete_case_kNN_classifier(x_test[i,:],X_train,Y_train,O_train):\n",
    "        accuracy_cc_kNN += 1/N_test\n",
    "end = time.time()\n",
    "run_time_cc_kNN = end-start\n",
    "print('Runtime Complete Case kNN (in s): ',np.round(run_time_cc_kNN,3))\n",
    "print('    Accuracy: ',np.round(accuracy_cc_kNN,3))\n",
    "    \n",
    "# Mean Imputation then kNN\n",
    "start = time.time()\n",
    "X_imputed = mean_impute(X_train, O_train)\n",
    "accuracy_mi_kNN = 0\n",
    "for i in range(N_test):\n",
    "    if y_test[i] == complete_case_kNN_classifier(x_test[i,:],X_imputed,Y_train,np.ones((N_train,d))):\n",
    "        accuracy_mi_kNN += 1/N_test\n",
    "end = time.time()\n",
    "run_time_mi_kNN = end-start\n",
    "print('Runtime Mean Imputation and kNN (in s): ',np.round(run_time_mi_kNN,3))\n",
    "print('    Accuracy: ',np.round(accuracy_mi_kNN,3))\n",
    "\n",
    "# c=0 Imputation then kNN\n",
    "start = time.time()\n",
    "X_imputed = constant_impute(X_train, O_train)\n",
    "accuracy_ci_kNN = 0\n",
    "for i in range(N_test):\n",
    "    if y_test[i] == complete_case_kNN_classifier(x_test[i,:],X_imputed,Y_train,np.ones((N_train,d))):\n",
    "        accuracy_ci_kNN += 1/N_test\n",
    "end = time.time()\n",
    "run_time_ci_kNN = end-start\n",
    "print('Runtime Constant Imputation and kNN (in s): ',np.round(run_time_ci_kNN,3))\n",
    "print('    Accuracy: ',np.round(accuracy_ci_kNN,3))\n",
    "\n",
    "# Oracle HAM\n",
    "start = time.time()\n",
    "Omega_star = []\n",
    "Omega_star.append(np.array([1,0],dtype=\"int\"))\n",
    "accuracy_oracle_HAM = 0\n",
    "for i in range(N_test):\n",
    "    if y_test[i] == HAM_classifier(x_test[i,:], Omega_star, X_train, Y_train, O_train):\n",
    "        accuracy_oracle_HAM += 1/N_test\n",
    "end = time.time()\n",
    "run_time_oracle_HAM = end-start\n",
    "print('Runtime Oracle HAM (in s): ',np.round(run_time_oracle_HAM,3))\n",
    "print('    Accuracy: ',np.round(accuracy_oracle_HAM,3))\n",
    "\n",
    "# Adaptive HAM\n",
    "start = time.time()\n",
    "Omega_hat = []\n",
    "Omega_hat = estimate_Omega_star(X_train, Y_train, O_train)\n",
    "accuracy_HAM = 0\n",
    "for i in range(N_test):\n",
    "    if y_test[i] == HAM_classifier(x_test[i,:], Omega_hat, X_train, Y_train, O_train):\n",
    "        accuracy_HAM += 1/N_test\n",
    "end = time.time()\n",
    "run_time_HAM = end-start\n",
    "print('Runtime HAM (in s): ',np.round(run_time_HAM,3))\n",
    "print('    Accuracy: ',np.round(accuracy_HAM,3))\n",
    "\n",
    "\n",
    "print('\\nEstimated runtime (in min): ',np.round(iterations*(run_time_ci_kNN+run_time_cc_kNN+run_time_mi_kNN+run_time_HAM+run_time_oracle_HAM)/60,3))\n",
    "\n",
    "\n",
    "''' \n",
    "Create training and test point sets, estimate empirical test error\n",
    "'''\n",
    "accuracy_cc_kNN = np.zeros(iterations)\n",
    "accuracy_mi_kNN = np.zeros(iterations)\n",
    "accuracy_ci_kNN = np.zeros(iterations)\n",
    "accuracy_oracle_HAM = np.zeros(iterations)\n",
    "accuracy_HAM = np.zeros(iterations)\n",
    "\n",
    "for it in range(iterations):\n",
    "    \n",
    "    # Generate Training Data \n",
    "    X_train = np.zeros((N_train,d))   \n",
    "    Y_train = np.zeros(N_train)\n",
    "    for i in range(N_train):\n",
    "        Y_train[i] = np.random.randint(2)   \n",
    "        X_train[i] = np.random.multivariate_normal(((-1)**Y_train[i])*u,Sigma)  \n",
    "    O_train = np.random.choice(2,size=(N_train,d),p=(1-p_MCAR,p_MCAR))\n",
    "\n",
    "    # Generate Test Points\n",
    "    x_test = np.zeros((N_test,d))\n",
    "    y_test = np.zeros(N_test)\n",
    "    for i in range(N_test):\n",
    "        y_test[i] = np.random.randint(2)\n",
    "        x_test[i,:] = np.random.multivariate_normal(((-1)**y_test[i])*u,Sigma) \n",
    "        \n",
    "    ''' Estimate Test Errors ''' \n",
    "    # Complete Case kNN\n",
    "    for i in range(N_test):\n",
    "        if y_test[i] == complete_case_kNN_classifier(x_test[i,:],X_train,Y_train,O_train):\n",
    "            accuracy_cc_kNN[it] += 1/N_test\n",
    "\n",
    "    # Mean Imputation then kNN  \n",
    "    for i in range(N_test):\n",
    "        X_imputed = mean_impute(X_train, O_train)\n",
    "        if y_test[i] == complete_case_kNN_classifier(x_test[i,:],X_imputed,Y_train,np.ones((N_train,d))):\n",
    "            accuracy_mi_kNN[it] += 1/N_test\n",
    "\n",
    "    # c=0 Imputation then kNN\n",
    "    for i in range(N_test):\n",
    "        X_imputed = constant_impute(X_train, O_train)\n",
    "        if y_test[i] == complete_case_kNN_classifier(x_test[i,:],X_imputed,Y_train,np.ones((N_train,d))):\n",
    "            accuracy_ci_kNN[it] += 1/N_test\n",
    "\n",
    "    # Oracle HAM\n",
    "    for i in range(N_test):\n",
    "        if y_test[i] == HAM_classifier(x_test[i,:], Omega_star, X_train, Y_train, O_train):\n",
    "            accuracy_oracle_HAM[it] += 1/N_test\n",
    "\n",
    "    # HAM\n",
    "    Omega_hat = []\n",
    "    Omega_hat = estimate_Omega_star(X_train, Y_train, O_train)\n",
    "    for i in range(N_test):\n",
    "        if y_test[i] == HAM_classifier(x_test[i,:], Omega_hat, X_train, Y_train, O_train):\n",
    "            accuracy_HAM[it] += 1/N_test\n",
    "    \n",
    "all_accuracies_cc_kNN[1,:] = accuracy_cc_kNN[0:100]\n",
    "all_accuracies_mi_kNN[1,:] = accuracy_mi_kNN[0:100]\n",
    "all_accuracies_ci_kNN[1,:] = accuracy_ci_kNN[0:100]\n",
    "all_accuracies_oracle_HAM[1,:] = accuracy_oracle_HAM[0:100]\n",
    "all_accuracies_HAM[1,:] = accuracy_HAM[0:100]\n",
    "    \n",
    "print('\\n\\nTest Accuracy Complete Case kNN: ',np.round(np.sum(accuracy_cc_kNN)/iterations,4))\n",
    "print('Test Accuracy Mean Imputation then kNN  : ',np.round(np.sum(accuracy_mi_kNN)/iterations,4))\n",
    "print('Test Accuracy c=0 Imputation then kNN: ',np.round(np.sum(accuracy_ci_kNN)/iterations,4))\n",
    "print('Test Accuracy Oracle HAM: ',np.round(np.sum(accuracy_oracle_HAM)/iterations,4))\n",
    "print('Test Accuracy HAM: ',np.round(np.sum(accuracy_HAM)/iterations,4))\n",
    "\n",
    "summary_accuracies = [accuracy_cc_kNN,accuracy_mi_kNN,accuracy_ci_kNN,accuracy_oracle_HAM,accuracy_HAM]\n",
    "summary_plot = sns.violinplot(summary_accuracies)\n",
    "\n",
    "summary_plot.set_xticklabels(['CC','MI kNN','CI kNN','oracle HAM','HAM'])\n",
    "\n",
    "plt.show(summary_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42ed9708",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T01:02:09.848233Z",
     "iopub.status.busy": "2023-05-11T01:02:09.847623Z",
     "iopub.status.idle": "2023-05-11T01:02:09.855355Z",
     "shell.execute_reply": "2023-05-11T01:02:09.855867Z"
    }
   },
   "outputs": [],
   "source": [
    "''' Save accuracies for further use '''\n",
    "\n",
    "np.save('Ex1_all_accuracies_cc_kNN',all_accuracies_cc_kNN)\n",
    "np.save('Ex1_all_accuracies_mi_kNN',all_accuracies_mi_kNN)\n",
    "np.save('Ex1_all_accuracies_ci_kNN',all_accuracies_ci_kNN)\n",
    "np.save('Ex1_all_accuracies_oracle_HAM',all_accuracies_oracle_HAM)\n",
    "np.save('Ex1_all_accuracies_HAM',all_accuracies_HAM)\n",
    "np.save('Ex1_Bayes_risk',Bayes_risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65ea970",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
