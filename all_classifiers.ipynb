{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "101fea5d",
   "metadata": {},
   "source": [
    "### Functions implemented \n",
    "\n",
    "A complete case k-nearest neighbour classifier, returns an estimated label for the test point:\n",
    "```python\n",
    "def complete_case_kNN_classifier(x_test, X_train, Y_train, O_train)\n",
    "```\n",
    "\n",
    "The HAM classifier is implemented, which is given an estimate $\\hat{\\Omega}$ of (or the true) $\\Omega^\\star$, and returns an estimated label of the test point. An estimate $\\hat{\\Omega}$ can be obtained from the training data using the second function:\n",
    "```python\n",
    "def HAM_classifier(x_test, Omega_hat, X_train, Y_train, O_train, alpha, betas, gammas)\n",
    "def estimate_Omega_star(X_train, Y_train, O_train, alpha, betas, gammas)\n",
    "```\n",
    "\n",
    "The HAM classifier make use of three auxiliary functions:\n",
    "```python\n",
    "def transform_j_to_omega(j_omega, d)\n",
    "def transform_omega_to_j(omega, d)\n",
    "def all_obs_patterns_of_length(d)\n",
    "```\n",
    "\n",
    "A cv algorithm estimates values for $\\alpha, \\boldsymbol{\\beta}, \\boldsymbol{\\gamma}$ using cross-validation and returns these in a list $[\\hat{\\alpha},\\hat{\\boldsymbol{\\beta}}, \\hat{\\boldsymbol{\\gamma}}]$:\n",
    "```python\n",
    "def estimate_params_CV(X_train, Y_train, O_train,L=5)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b28da6e",
   "metadata": {},
   "source": [
    "# Complete case kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1549294",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "complete case k-nearest neighbour classifier\n",
    "\"\"\"\n",
    "        \n",
    "        \n",
    "''' Predict value of test point using all available cases '''\n",
    "def complete_case_kNN_classifier(x_test, X_train, Y_train, O_train):\n",
    "    mc_distances = []\n",
    "    mc_y = []\n",
    "    no_matching_cases = 0\n",
    "    \n",
    "    for i in range(N_train):\n",
    "        if np.all(np.ones(d)<=O_train[i,:]):\n",
    "            no_matching_cases += 1\n",
    "            dist = 0\n",
    "            for j in range(d):\n",
    "                dist += (x_test[j]-X_train[i,j])**2\n",
    "            mc_distances.append(np.sqrt(dist))\n",
    "            mc_y.append(Y_train[i])\n",
    "            \n",
    "    sort_index = np.argsort(mc_distances)\n",
    "    k_mc = int(np.rint(1/3 * no_matching_cases**(1/(3+d))))\n",
    "    \n",
    "    if no_matching_cases==0:\n",
    "        if np.random.uniform()<1/2:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    else:\n",
    "        eta_sum = 0\n",
    "        for i in range(k_mc):\n",
    "            eta_sum += 1/k_mc * mc_y[sort_index[i]]\n",
    "\n",
    "        if eta_sum<1/2:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e18c5b",
   "metadata": {},
   "source": [
    "# HAM\n",
    "\n",
    "### Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139f65fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "NB: (0,1,0,0,1,0,1) will be the 0100101_2-th = 37_10-th entry. Can transform by taking \n",
    "omega = (omega_1,...,omega_d-1,omega_d) --> corresponding j=omega_d+2*omega_d-1+4*omega_d-2+...+2^(d-1)*omega_1\n",
    "and also in the other direction\n",
    "omega_d = j mod2, omega_d-1=((j-omega_d)/2) mod2, omega_d-2 = ((j-omega_d-omega_d-2)/4) mod2, et cetera.\n",
    "This is implemented in the next two functions.\n",
    "\"\"\"\n",
    "def transform_j_to_omega(j_omega, d):\n",
    "    omega=np.zeros(d,dtype=\"int\")\n",
    "    j=0\n",
    "    j+=j_omega\n",
    "    \n",
    "    for k in range(d):\n",
    "        omega[d-1-k]=j%2\n",
    "        j=(j-omega[d-1-k])/2\n",
    "    return omega\n",
    "\n",
    "def transform_omega_to_j(omega, d):\n",
    "    j=0\n",
    "    for k in range(d):\n",
    "        j+=omega[d-1-k]*(2**k)\n",
    "    return j \n",
    "\n",
    "\n",
    "''' To create a list with all possible observation patterns we firstly define the following functions '''\n",
    "def all_obs_patterns_of_length(d):\n",
    "    pattern_list = []\n",
    "    omega=np.zeros(d,dtype=\"int\")\n",
    "\n",
    "    for k in range(d+1):\n",
    "        pattern_list.append([])\n",
    "        \n",
    "    for j in range(2**d):\n",
    "        omega = transform_j_to_omega(j,d)\n",
    "        o = int(np.sum(omega))\n",
    "        pattern_list[o].append(omega)\n",
    "        \n",
    "    return pattern_list\n",
    "\n",
    "    \n",
    "\"\"\" Create a list with all possible observation patterns of length l with o observations (as np arrays), sorted by the number of observed values \"\"\"\n",
    "obs_patterns_with_o_observations_and_length_d = []\n",
    "obs_patterns_with_o_observations_and_length_d.append([])\n",
    "for l in range(1,d+1):\n",
    "    obs_patterns_with_o_observations_and_length_d.append(all_obs_patterns_of_length(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0264dd72",
   "metadata": {},
   "source": [
    "### HAM\n",
    "Oracle if given the true $\\Omega$ instead of $\\hat{\\Omega}$, otherwise $\\hat{\\Omega}$ needs to be estimated from the data (see below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1330c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Predict value of fully observed test point using missing data anova decomposition '''\n",
    "def HAM_classifier(x_test, Omega_hat, X_train, Y_train, O_train, alpha, betas, gammas):\n",
    "    \n",
    "    # f_0 is the expectation of Y-1/2\n",
    "    f_hat_0 = sum(Y_train)/len(Y_train) - 1/2\n",
    "    \n",
    "    \"\"\" Estimate f_omega at test point for each observation pattern \"\"\"   \n",
    "    f_hat_omega = np.zeros(2**d)\n",
    "    f_hat_omega[0] = f_hat_0 \n",
    "    \n",
    "    ''' Iterate through the different observation patterns '''\n",
    "    for o in range(1,d+1):\n",
    "        l_max = len(obs_patterns_with_o_observations_and_length_d[d][o])\n",
    "        for omega_d_o in range(l_max):\n",
    "            \n",
    "            # get observation pattern, transform to index\n",
    "            omega = obs_patterns_with_o_observations_and_length_d[d][o][omega_d_o]\n",
    "            j_omega = transform_omega_to_j(omega,d)\n",
    "            \n",
    "            # calculate number of available cases\n",
    "            N_available = 0\n",
    "            for it in range(N_train):\n",
    "                if (omega<=O_train[it,:]).all():\n",
    "                    N_available += 1\n",
    "            \n",
    "            # calculate \n",
    "            if N_available>0:\n",
    "                beta_omega = np.min(betas+(omega-1)*(-1000))\n",
    "                gamma_omega = np.min(gammas+(omega-1)*(-1000))\n",
    "                if gamma_omega==100:\n",
    "                    exponent = beta_omega/(2*beta_omega+sum(omega))\n",
    "                else:\n",
    "                    exponent = beta_omega*gamma_omega/(gamma_omega*(2*beta_omega+sum(omega))+alpha*beta_omega)\n",
    "                k_omega = 1+int(np.floor(N_available**(2*exponent)))\n",
    "                        \n",
    "            # Estimate f_omega at test point\n",
    "            if N_available>0:\n",
    "\n",
    "                # compute distances to test point, only considering the w-observed variables\n",
    "                distances = []\n",
    "                for i in range(N_train):\n",
    "                    if (omega<=O_train[i,:]).all():\n",
    "                        dist = 0\n",
    "                        for k in range(d):\n",
    "                            if omega[k]==1:\n",
    "                                dist += (x_test[k]-X_train[i,k])**2\n",
    "                        distances.append(np.sqrt(dist))\n",
    "                    else:\n",
    "                        distances.append(10000.0) # make sure that unavailable data points are not a nearest neighbour\n",
    "\n",
    "                # sort distances\n",
    "                sort_index = np.argsort(distances)\n",
    "\n",
    "                # add Monte Carlo estimate of eta to f_omega\n",
    "                for i in range(k_omega):\n",
    "                    f_hat_omega[j_omega] += 1/k_omega * Y_train[sort_index[i]] \n",
    "\n",
    "                # substract 1/2 from the estimate\n",
    "                f_hat_omega[j_omega] -= 1/2\n",
    "\n",
    "                # substract Monte Carlo estimates of f_{omega_subset} from f_omega\n",
    "                omega_subset = np.zeros(d,dtype=\"int\")\n",
    "                for j_short in range(2**o-1):\n",
    "                    omega_short = transform_j_to_omega(j_short,o)\n",
    "                    omega_subset = 0*omega_subset\n",
    "                    omega_subset[np.nonzero(omega)] = omega_short\n",
    "                    j_subset = transform_omega_to_j(omega_subset,d)\n",
    "\n",
    "                    f_hat_omega[j_omega] -= f_hat_omega[j_subset]\n",
    "  \n",
    "        \n",
    "    ''' Estimate eta '''\n",
    "    eta_test = 1/2\n",
    "    for o in range(d+1):\n",
    "        l_max = len(obs_patterns_with_o_observations_and_length_d[d][o])\n",
    "        for omega_d_o in range(l_max):\n",
    "            \n",
    "            # get observation pattern, transform to index\n",
    "            omega = obs_patterns_with_o_observations_and_length_d[d][o][omega_d_o]\n",
    "            j_omega = transform_omega_to_j(omega,d)\n",
    "            \n",
    "            # check if omega<= element for some element in Omega_hat, return 1 if this is the case\n",
    "            helpy = 0 \n",
    "            for elem in Omega_hat:\n",
    "                if (omega<=elem).all():\n",
    "                    helpy = 1\n",
    "                    \n",
    "            # if intersection is empty, add omega to Omega_hat\n",
    "            if helpy == 1:\n",
    "                eta_test += f_hat_omega[j_omega]\n",
    "                            \n",
    "    if eta_test<1/2:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd91de0",
   "metadata": {},
   "source": [
    "### Estimate the relevant terms in the anova decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a8e84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Estimate Omega_star using missing data anova decomposition '''\n",
    "def estimate_Omega_star(X_train, Y_train, O_train, alpha, betas, gammas):\n",
    "    \n",
    "    # Quantities needed for thresholding\n",
    "    tau_omega = np.ones(2**d)\n",
    "    sigma_hat_omega_sq = np.zeros(2**d)\n",
    "    \n",
    "    # f_0 is the expectation of Y-1/2\n",
    "    f_hat_0 = sum(Y_train)/len(Y_train) - 1/2\n",
    "    sigma_hat_omega_sq[0] = f_hat_0**2\n",
    "    \n",
    "    \"\"\" Estimate f_omega at all training points for each observation pattern \"\"\"   \n",
    "    f_hat_omega = np.zeros((N_train,2**d))\n",
    "    f_hat_omega[:,0] = f_hat_0*np.ones(N_train) \n",
    "    \n",
    "    ''' Iterate through the different observation patterns '''\n",
    "    for o in range(1,d+1):\n",
    "        l_max = len(obs_patterns_with_o_observations_and_length_d[d][o])\n",
    "        for omega_d_o in range(l_max):\n",
    "            \n",
    "            # get observation pattern, transform to index\n",
    "            omega = obs_patterns_with_o_observations_and_length_d[d][o][omega_d_o]\n",
    "            j_omega = transform_omega_to_j(omega,d)\n",
    "            \n",
    "            # calculate number of available cases\n",
    "            N_available = 0\n",
    "            for it in range(N_train):\n",
    "                if (omega<=O_train[it,:]).all():\n",
    "                    N_available += 1\n",
    "            \n",
    "            # calculate \n",
    "            if N_available>0:\n",
    "                beta_omega = np.min(betas+(omega-1)*(-1000))\n",
    "                gamma_omega = np.min(gammas+(omega-1)*(-1000))\n",
    "                if gamma_omega==100:\n",
    "                    exponent = beta_omega/(2*beta_omega+sum(omega))\n",
    "                else:\n",
    "                    exponent = beta_omega*gamma_omega/(gamma_omega*(2*beta_omega+sum(omega))+alpha*beta_omega)\n",
    "                k_omega = 1+int(np.floor(N_available**(2*exponent)))\n",
    "                tau_omega[j_omega] = 1/(N_available**(exponent/2))/16\n",
    "            \n",
    "            # For all training points that are available cases for the observation pattern\n",
    "            for it in range(N_train):\n",
    "                if (omega<=O_train[it,:]).all() and N_available>=1:\n",
    "            \n",
    "                    # compute distances to all other training points, only considering the w-observed variables\n",
    "                    distances = []\n",
    "                    for i in range(N_train):\n",
    "                        if (omega<=O_train[i,:]).all():\n",
    "                            dist = 0\n",
    "                            for k in range(d):\n",
    "                                if omega[k]==1:\n",
    "                                    dist += (X_train[it,k]-X_train[i,k])**2\n",
    "                            distances.append(np.sqrt(dist))\n",
    "                        else:\n",
    "                            distances.append(1000) # make sure that unavailable data points are not a nearest neighbour\n",
    "\n",
    "                    # sort distances and decide on k_omega and the threshold tau_omega\n",
    "                    sort_index = np.argsort(distances)\n",
    "\n",
    "                    # add Monte Carlo estimate of eta to f_omega\n",
    "                    for i in range(k_omega):\n",
    "                        f_hat_omega[it,j_omega] += 1/k_omega * Y_train[sort_index[i]] \n",
    "\n",
    "                    # substract 1/2 from the estimate\n",
    "                    f_hat_omega[it,j_omega] -= 1/2\n",
    "\n",
    "                    # substract Monte Carlo estimates of f_{omega_subset} from f_omega\n",
    "                    omega_subset = np.zeros(d,dtype=\"int\")\n",
    "                    for j_short in range(2**o-1):\n",
    "                        omega_short = transform_j_to_omega(j_short,o)\n",
    "                        omega_subset = 0*omega_subset\n",
    "                        omega_subset[np.nonzero(omega)] = omega_short\n",
    "                        j_subset = transform_omega_to_j(omega_subset,d)\n",
    "\n",
    "                        f_hat_omega[it,j_omega] -= f_hat_omega[it,j_subset]\n",
    "                    \n",
    "            # Calculate Sobol index                   \n",
    "            if N_available>0:\n",
    "                sigma_hat_omega_sq[j_omega] = 1/N_available * np.sum(f_hat_omega[0:N_train,j_omega]**2)     \n",
    "\n",
    "    \"\"\" Estimate Omega_hat \"\"\"                        \n",
    "    Omega_hat = []\n",
    "    Omega_hat_cup_L_Omega_hat = []\n",
    "    \n",
    "    ''' Iterate through the different observation patterns, starting from the fully observed one '''\n",
    "    for d_prime in range(d+1):\n",
    "        \n",
    "        l_max = len(obs_patterns_with_o_observations_and_length_d[d][d-d_prime])\n",
    "        for omega_d_d_prime in range(l_max):\n",
    "            \n",
    "            # get observation pattern, transform to index\n",
    "            omega = obs_patterns_with_o_observations_and_length_d[d][d-d_prime][omega_d_d_prime]\n",
    "            \n",
    "            # check if U({omega}) intersect hat_Omega is empty, return 0 if this is the case\n",
    "            helpy = 0 \n",
    "            for elem in Omega_hat_cup_L_Omega_hat:\n",
    "                if (elem==omega).all():\n",
    "                    helpy = 1\n",
    "                    \n",
    "            # if intersection is empty, add omega to Omega_hat and L(omega) to Omega_hat_cup_L_Omega_hat\n",
    "            if helpy == 0:\n",
    "                j_omega = transform_omega_to_j(omega,d)\n",
    "                if sigma_hat_omega_sq[j_omega] >= tau_omega[j_omega]:\n",
    "                    Omega_hat.append(omega)\n",
    "                    omega_subset = np.zeros(d,dtype=\"int\")\n",
    "                    for j_short in range(2**(d-d_prime)):\n",
    "                        omega_short = transform_j_to_omega(j_short,d-d_prime)\n",
    "                        omega_subset = 0*omega_subset\n",
    "                        omega_subset[np.nonzero(omega)] = omega_short\n",
    "                        Omega_hat_cup_L_Omega_hat.append(omega_subset)\n",
    "        \n",
    "    return Omega_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11960413",
   "metadata": {},
   "source": [
    "### cv HAM\n",
    "\n",
    "Cross-validation version of the HAM, optimal values for $\\alpha$, each $\\beta_j$, and each $\\gamma_j$, from which a set of $k_\\omega$s is calculated. These are returned and can then be used in the HAM classifier above. \n",
    "\n",
    "As a first step, a list with every possible combination of the parameters is initialised, where each list element contains: $[\\alpha,(\\beta_1,\\ldots,\\beta_d),(\\gamma_1,\\ldots,\\gamma_d)]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dba5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_vals = [0,1/2,1,d]\n",
    "beta_j_vals = [1/4,1/2,3/4,1]\n",
    "gamma_j_vals = [1/2,1,2,100.0] # 100 will be coded as infinity later on\n",
    "\n",
    "beta_vals = []\n",
    "for j in range(len(beta_j_vals)):\n",
    "    if d==2:\n",
    "        beta_vals.append(np.array([beta_j_vals[j],beta_j_vals[j]]))\n",
    "    elif d==3:\n",
    "        beta_vals.append(np.array([beta_j_vals[j],beta_j_vals[j],beta_j_vals[j]]))\n",
    "    elif d==4:\n",
    "        beta_vals.append(np.array([beta_j_vals[j],beta_j_vals[j],beta_j_vals[j],beta_j_vals[j]]))\n",
    "    elif d==5:\n",
    "        beta_vals.append(np.array([beta_j_vals[j],beta_j_vals[j],beta_j_vals[j],beta_j_vals[j],beta_j_vals[j]]))\n",
    "    elif d==7:\n",
    "        beta_vals.append(np.array([beta_j_vals[j],beta_j_vals[j],beta_j_vals[j],beta_j_vals[j],beta_j_vals[j],beta_j_vals[j],beta_j_vals[j]]))\n",
    "    else:\n",
    "        print('Error in the initialisation of the CV values, d must be in {2,3,4,5,7}.') \n",
    "\n",
    "gamma_vals = []    \n",
    "for j in range(len(gamma_j_vals)):\n",
    "    if d==2:\n",
    "        gamma_vals.append(np.array([gamma_j_vals[j],gamma_j_vals[j]]))\n",
    "    elif d==3:\n",
    "        gamma_vals.append(np.array([gamma_j_vals[j],gamma_j_vals[j],gamma_j_vals[j]]))\n",
    "    elif d==4:\n",
    "        gamma_vals.append(np.array([gamma_j_vals[j],gamma_j_vals[j],gamma_j_vals[j],gamma_j_vals[j]]))\n",
    "    elif d==5:\n",
    "        gamma_vals.append(np.array([gamma_j_vals[j],gamma_j_vals[j],gamma_j_vals[j],gamma_j_vals[j],gamma_j_vals[j]]))\n",
    "    elif d==7:\n",
    "        gamma_vals.append(np.array([gamma_j_vals[j],gamma_j_vals[j],gamma_j_vals[j],gamma_j_vals[j],gamma_j_vals[j],gamma_j_vals[j],gamma_j_vals[j]]))\n",
    "\n",
    "CV_vals = []\n",
    "for i in range(len(alpha_vals)):\n",
    "    for j in range(len(beta_vals)):\n",
    "        for k in range(len(gamma_vals)):                \n",
    "            CV_vals.append([alpha_vals[i],beta_vals[j],gamma_vals[k]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746ca7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Estimate Omega_star using missing data anova decomposition '''\n",
    "def estimate_params_CV(X_train, Y_train, O_train,L=5):\n",
    "    \n",
    "    # Additional parameters are R (number of different values for k tried) and L (number of CV folds)\n",
    "    \n",
    "    ''' Cross validation parameters and errors are initialised and subsequently computed '''\n",
    "    N_test_CV = int(N_train/L)\n",
    "    if N_test_CV*L!=N_train:\n",
    "        print('Error in CV folds')\n",
    "    N_train_CV = N_train - N_test_CV\n",
    "    \n",
    "    CV_errors = np.zeros(len(CV_vals))  # will be used to store the smallest error in CV\n",
    "    X_train_CV = np.zeros((N_train_CV,d))\n",
    "    X_test_CV = np.zeros((N_test_CV,d))\n",
    "    O_train_CV = np.zeros((N_train_CV,d))\n",
    "    O_test_CV = np.zeros((N_test_CV,d))\n",
    "    Y_train_CV = np.zeros(N_train_CV) \n",
    "    Y_test_CV = np.zeros(N_test_CV)\n",
    "    \n",
    "    Omega_hat = [np.ones(d,dtype=\"int\")]\n",
    "    \n",
    "    for r in range(len(CV_vals)):\n",
    "        for l in range(L):\n",
    "            \n",
    "            # Leave out part of the training data for cross validation\n",
    "            X_train_CV[0:l*N_test_CV,:] = X_train[0:l*N_test_CV,:]\n",
    "            X_test_CV[:,:] = X_train[l*N_test_CV:(l+1)*N_test_CV,:]\n",
    "            X_train_CV[l*N_test_CV:N_train_CV,:] = X_train[(l+1)*N_test_CV:N_train,:]\n",
    "            O_train_CV[0:l*N_test_CV,:] = O_train[0:l*N_test_CV,:]\n",
    "            O_test_CV[:,:] = O_train[l*N_test_CV:(l+1)*N_test_CV,:]\n",
    "            O_train_CV[l*N_test_CV:N_train_CV,:] = O_train[(l+1)*N_test_CV:N_train,:]\n",
    "            Y_train_CV[0:l*N_test_CV] = Y_train[0:l*N_test_CV]\n",
    "            Y_test_CV = Y_train[l*N_test_CV:(l+1)*N_test_CV]\n",
    "            Y_train_CV[l*N_test_CV:N_train_CV] = Y_train[(l+1)*N_test_CV:N_train]\n",
    "                   \n",
    "            Omega_hat = [np.ones(d,dtype=\"int\")]\n",
    "        \n",
    "            \"\"\" \n",
    "            Calculate test error on the left out set\n",
    "            \"\"\"                    \n",
    "            for it in range(N_test_CV):\n",
    "                x_test = X_test_CV[it,:]\n",
    "                \n",
    "                # f_0 is the expectation of Y-1/2\n",
    "                f_hat_0 = sum(Y_train_CV)/len(Y_train_CV) - 1/2\n",
    "\n",
    "                \"\"\" Estimate f_omega at test point for each observation pattern \"\"\"   \n",
    "                f_hat_omega = np.zeros(2**d)\n",
    "                f_hat_omega[0] = f_hat_0 \n",
    "\n",
    "                ''' Iterate through the different observation patterns '''\n",
    "                for o in range(1,d+1):\n",
    "                    l_max = len(obs_patterns_with_o_observations_and_length_d[d][o])\n",
    "                    for omega_d_o in range(l_max):\n",
    "\n",
    "                        # get observation pattern, transform to index\n",
    "                        omega = obs_patterns_with_o_observations_and_length_d[d][o][omega_d_o]\n",
    "                        j_omega = transform_omega_to_j(omega,d)\n",
    "\n",
    "                        if (omega<=O_test_CV[it,:]).all():\n",
    "\n",
    "                            # calculate number of available cases\n",
    "                            N_available = 0\n",
    "                            for i in range(N_train_CV):\n",
    "                                if (omega<=O_train_CV[i,:]).all():\n",
    "                                    N_available += 1\n",
    "\n",
    "                            # calculate \n",
    "                            if N_available>0:\n",
    "                                alpha = CV_vals[r][0]\n",
    "                                beta_omega = np.min(CV_vals[r][1]+(omega-1)*(-1000))\n",
    "                                gamma_omega = np.min(CV_vals[r][2]+(omega-1)*(-1000))\n",
    "                                if gamma_omega!=100:\n",
    "                                    exponent = beta_omega*gamma_omega/(gamma_omega*(2*beta_omega+sum(omega))+alpha*beta_omega)\n",
    "                                else:\n",
    "                                    exponent = beta_omega/(2*beta_omega+sum(omega))\n",
    "                                k_omega = 1+int(np.floor(N_available**(2*exponent)))\n",
    "\n",
    "                            # Estimate f_omega at test point\n",
    "                            if N_available>0:\n",
    "\n",
    "                                # compute distances to test point, only considering the w-observed variables\n",
    "                                distances = []\n",
    "                                for i in range(N_train_CV):\n",
    "                                    if (omega<=O_train_CV[i,:]).all():\n",
    "                                        dist = 0\n",
    "                                        for k in range(d):\n",
    "                                            if omega[k]==1:\n",
    "                                                dist += (x_test[k]-X_train_CV[i,k])**2\n",
    "                                        distances.append(np.sqrt(dist))\n",
    "                                    else:\n",
    "                                        distances.append(10000.0) # make sure that unavailable data points are not a nearest neighbour\n",
    "\n",
    "                                # sort distances\n",
    "                                sort_index = np.argsort(distances)\n",
    "\n",
    "                                # add Monte Carlo estimate of eta to f_omega\n",
    "                                for i in range(k_omega):\n",
    "                                    f_hat_omega[j_omega] += 1/k_omega * Y_train_CV[sort_index[i]] \n",
    "\n",
    "                                # substract 1/2 from the estimate\n",
    "                                f_hat_omega[j_omega] -= 1/2\n",
    "\n",
    "                                # substract Monte Carlo estimates of f_{omega_subset} from f_omega\n",
    "                                omega_subset = np.zeros(d,dtype=\"int\")\n",
    "                                for j_short in range(2**o-1):\n",
    "                                    omega_short = transform_j_to_omega(j_short,o)\n",
    "                                    omega_subset = 0*omega_subset\n",
    "                                    omega_subset[np.nonzero(omega)] = omega_short\n",
    "                                    j_subset = transform_omega_to_j(omega_subset,d)\n",
    "\n",
    "                                    f_hat_omega[j_omega] -= f_hat_omega[j_subset]\n",
    "\n",
    "\n",
    "                ''' Estimate eta '''\n",
    "                eta_test = 1/2\n",
    "                for o in range(d+1):\n",
    "                    l_max = len(obs_patterns_with_o_observations_and_length_d[d][o])\n",
    "                    for omega_d_o in range(l_max):\n",
    "\n",
    "                        # get observation pattern, transform to index\n",
    "                        omega = obs_patterns_with_o_observations_and_length_d[d][o][omega_d_o]\n",
    "                        j_omega = transform_omega_to_j(omega,d)\n",
    "\n",
    "                        # check if omega<= element for some element in Omega_hat, return 1 if this is the case\n",
    "                        helpy = 0 \n",
    "                        for elem in Omega_hat:\n",
    "                            if (omega<=elem).all():\n",
    "                                helpy = 1\n",
    "\n",
    "                        # if intersection is empty, add omega to Omega_hat\n",
    "                        if helpy == 1:\n",
    "                            eta_test += f_hat_omega[j_omega]\n",
    "\n",
    "                if eta_test<1/2 and Y_test_CV[it]==1:\n",
    "                    CV_errors[r] += 1\n",
    "                elif eta_test>=1/2 and Y_test_CV[it]==0:\n",
    "                    CV_errors[r] += 1\n",
    "                \n",
    "    r_optimal = np.argmin(CV_errors)\n",
    "        \n",
    "    return CV_vals[r_optimal] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
