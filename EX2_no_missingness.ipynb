{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6511e7a",
   "metadata": {},
   "source": [
    "### Functions implemented \n",
    "\n",
    "A complete case k-nearest neighbour classifier, returns an estimated label for the test point:\n",
    "```python\n",
    "def complete_case_kNN_classifier(x_test, X_train, Y_train, O_train)\n",
    "```\n",
    "\n",
    "Two imputation methods can be called, both require only the training data and the observations patterns thereof as inputs, they return an imputed data set of the same size as X_train. The first one imputes with a constant (default is $0$ unless specified otherwise by the user), the second one with the mean of all observed variables.\n",
    "```python\n",
    "def constant_impute(X_train, O_train, c=0)\n",
    "def mean_impute(X_train, O_train)\n",
    "```\n",
    "\n",
    "The HAM classifier is implemented, which is given an estimate $\\hat{\\Omega}$ of (or the true) $\\Omega^\\star$, and returns an estimated label of the test point. An estimate $\\hat{\\Omega}$ can be obtained from the training data using the second function:\n",
    "```python\n",
    "def HAM_classifier(x_test, Omega_hat, X_train, Y_train, O_train)\n",
    "def estimate_Omega_star(X_train, Y_train, O_train)\n",
    "```\n",
    "\n",
    "The HAM classifier make use of three auxiliary functions:\n",
    "```python\n",
    "def transform_j_to_omega(j_omega, d)\n",
    "def transform_omega_to_j(omega, d)\n",
    "def all_obs_patterns_of_length(d)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d12774a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T20:49:50.377091Z",
     "iopub.status.busy": "2023-05-17T20:49:50.374927Z",
     "iopub.status.idle": "2023-05-17T20:49:52.523714Z",
     "shell.execute_reply": "2023-05-17T20:49:52.524149Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "d = 5\n",
    "beta = 1\n",
    "alpha = 1\n",
    "gamma = np.ones(2**d)\n",
    "gamma_max = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6238303",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T20:49:52.531745Z",
     "iopub.status.busy": "2023-05-17T20:49:52.531132Z",
     "iopub.status.idle": "2023-05-17T20:49:52.533089Z",
     "shell.execute_reply": "2023-05-17T20:49:52.533654Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "complete case k-nearest neighbour classifier\n",
    "\"\"\"\n",
    "        \n",
    "        \n",
    "''' Predict value of test point using all available cases '''\n",
    "def complete_case_kNN_classifier(x_test, X_train, Y_train, O_train):\n",
    "    mc_distances = []\n",
    "    mc_y = []\n",
    "    no_matching_cases = 0\n",
    "    \n",
    "    for i in range(N_train):\n",
    "        if np.all(np.ones(d)<=O_train[i,:]):\n",
    "            no_matching_cases += 1\n",
    "            dist = 0\n",
    "            for j in range(d):\n",
    "                dist += (x_test[j]-X_train[i,j])**2\n",
    "            mc_distances.append(np.sqrt(dist))\n",
    "            mc_y.append(Y_train[i])\n",
    "            \n",
    "    sort_index = np.argsort(mc_distances)\n",
    "    k_mc = int(np.rint(1/3 * no_matching_cases**(beta*gamma_max*(1+alpha)/(gamma_max*(2*beta+d)+alpha*beta))))\n",
    "    \n",
    "    if no_matching_cases==0:\n",
    "        if np.random.uniform()<1/2:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    else:\n",
    "        eta_sum = 0\n",
    "        for i in range(k_mc):\n",
    "            eta_sum += 1/k_mc * mc_y[sort_index[i]]\n",
    "\n",
    "        if eta_sum<1/2:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0c4dbf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T20:49:52.539875Z",
     "iopub.status.busy": "2023-05-17T20:49:52.539286Z",
     "iopub.status.idle": "2023-05-17T20:49:52.541385Z",
     "shell.execute_reply": "2023-05-17T20:49:52.541787Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Imputation methods\n",
    "\"\"\"\n",
    "\n",
    "def constant_impute(X_train, O_train, c=0):\n",
    "    X_imputed = np.zeros((N_train,d))\n",
    "    X_imputed += X_train\n",
    "    if c!=0:\n",
    "        for it in range(N_train):\n",
    "            for i in range(d):\n",
    "                if O_train[it,i]==0:\n",
    "                    X_imputed[it,i] = c\n",
    "    return X_imputed\n",
    "\n",
    "def mean_impute(X_train, O_train):\n",
    "    X_imputed = np.zeros((N_train,d))\n",
    "    X_imputed += X_train\n",
    "    \n",
    "    means = np.zeros(d)\n",
    "    for i in range(d):\n",
    "        means[i] = np.sum(X_train[:,i])/np.sum(O_train[:,i])\n",
    "    \n",
    "    for it in range(N_train):\n",
    "        for i in range(d):\n",
    "            if O_train[it,i]==0:\n",
    "                X_imputed[it,i] = means[i]\n",
    "    return X_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfb71ada",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T20:49:52.550236Z",
     "iopub.status.busy": "2023-05-17T20:49:52.549620Z",
     "iopub.status.idle": "2023-05-17T20:49:52.552159Z",
     "shell.execute_reply": "2023-05-17T20:49:52.552717Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[array([0, 0, 0])], [array([0, 0, 1]), array([0, 1, 0]), array([1, 0, 0])], [array([0, 1, 1]), array([1, 0, 1]), array([1, 1, 0])], [array([1, 1, 1])]]\n",
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "NB: (0,1,0,0,1,0,1) will be the 0100101_2-th = 37_10-th entry. Can transform by taking \n",
    "omega = (omega_1,...,omega_d-1,omega_d) --> corresponding j=omega_d+2*omega_d-1+4*omega_d-2+...+2^(d-1)*omega_1\n",
    "and also in the other direction\n",
    "omega_d = j mod2, omega_d-1=((j-omega_d)/2) mod2, omega_d-2 = ((j-omega_d-omega_d-2)/4) mod2, et cetera.\n",
    "This is implemented in the next two functions.\n",
    "\"\"\"\n",
    "def transform_j_to_omega(j_omega, d):\n",
    "    omega=np.zeros(d,dtype=\"int\")\n",
    "    j=0\n",
    "    j+=j_omega\n",
    "    \n",
    "    for k in range(d):\n",
    "        omega[d-1-k]=j%2\n",
    "        j=(j-omega[d-1-k])/2\n",
    "    return omega\n",
    "\n",
    "def transform_omega_to_j(omega, d):\n",
    "    j=0\n",
    "    for k in range(d):\n",
    "        j+=omega[d-1-k]*(2**k)\n",
    "    return j \n",
    "\n",
    "\n",
    "''' To create a list with all possible observation patterns we firstly define the following functions '''\n",
    "def all_obs_patterns_of_length(d):\n",
    "    pattern_list = []\n",
    "    omega=np.zeros(d,dtype=\"int\")\n",
    "\n",
    "    for k in range(d+1):\n",
    "        pattern_list.append([])\n",
    "        \n",
    "    for j in range(2**d):\n",
    "        omega = transform_j_to_omega(j,d)\n",
    "        o = int(np.sum(omega))\n",
    "        pattern_list[o].append(omega)\n",
    "        \n",
    "    return pattern_list\n",
    "\n",
    "    \n",
    "\"\"\" Create a list with all possible observation patterns of length l with o observations (as np arrays), sorted by the number of observed values \"\"\"\n",
    "obs_patterns_with_o_observations_and_length_d = []\n",
    "obs_patterns_with_o_observations_and_length_d.append([])\n",
    "for l in range(1,d+1):\n",
    "    obs_patterns_with_o_observations_and_length_d.append(all_obs_patterns_of_length(l))\n",
    "\n",
    "\"\"\" Check that these are the correct observations patterns \"\"\"    \n",
    "print(obs_patterns_with_o_observations_and_length_d[3])\n",
    "print(obs_patterns_with_o_observations_and_length_d[2][1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa445d09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T20:49:52.563719Z",
     "iopub.status.busy": "2023-05-17T20:49:52.563016Z",
     "iopub.status.idle": "2023-05-17T20:49:52.564928Z",
     "shell.execute_reply": "2023-05-17T20:49:52.565376Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "HAM Classifier\n",
    "\"\"\"\n",
    "\n",
    "''' Predict value of fully observed test point using missing data anova decomposition '''\n",
    "def HAM_classifier(x_test, Omega_hat, X_train, Y_train, O_train):\n",
    "    \n",
    "    # f_0 is the expectation of Y-1/2\n",
    "    f_hat_0 = sum(Y_train)/len(Y_train) - 1/2\n",
    "    \n",
    "    \"\"\" Estimate f_omega at test point for each observation pattern \"\"\"   \n",
    "    f_hat_omega = np.zeros(2**d)\n",
    "    f_hat_omega[0] = f_hat_0 \n",
    "    \n",
    "    ''' Iterate through the different observation patterns '''\n",
    "    for o in range(1,d+1):\n",
    "        l_max = len(obs_patterns_with_o_observations_and_length_d[d][o])\n",
    "        for omega_d_o in range(l_max):\n",
    "            \n",
    "            # get observation pattern, transform to index\n",
    "            omega = obs_patterns_with_o_observations_and_length_d[d][o][omega_d_o]\n",
    "            j_omega = transform_omega_to_j(omega,d)\n",
    "            \n",
    "            # calculate number of available cases\n",
    "            N_available = 0\n",
    "            for it in range(N_train):\n",
    "                if (omega<=O_train[it,:]).all():\n",
    "                    N_available += 1\n",
    "            \n",
    "            # calculate \n",
    "            if N_available>0:\n",
    "                gamma_omega = 1#np.amax(gamma*omega)\n",
    "                exponent = beta*gamma_omega/(gamma_omega*(2*beta+sum(omega))+alpha*beta)\n",
    "                k_omega = 1+int(np.floor(N_available**(2*exponent)))\n",
    "                        \n",
    "            # Estimate f_omega at test point\n",
    "            if N_available>=1:\n",
    "\n",
    "                # compute distances to test point, only considering the w-observed variables\n",
    "                distances = []\n",
    "                for i in range(N_train):\n",
    "                    if (omega<=O_train[i,:]).all():\n",
    "                        dist = 0\n",
    "                        for k in range(d):\n",
    "                            if omega[k]==1:\n",
    "                                dist += (x_test[k]-X_train[i,k])**2\n",
    "                        distances.append(np.sqrt(dist))\n",
    "                    else:\n",
    "                        distances.append(100.0) # make sure that unavailable data points are not a nearest neighbour\n",
    "\n",
    "                # sort distances\n",
    "                sort_index = np.argsort(distances)\n",
    "\n",
    "                # add Monte Carlo estimate of eta to f_omega\n",
    "                for i in range(k_omega):\n",
    "                    f_hat_omega[j_omega] += 1/k_omega * Y_train[sort_index[i]] \n",
    "\n",
    "                # substract 1/2 from the estimate\n",
    "                f_hat_omega[j_omega] -= 1/2\n",
    "\n",
    "                # substract Monte Carlo estimates of f_{omega_subset} from f_omega\n",
    "                omega_subset = np.zeros(d,dtype=\"int\")\n",
    "                for j_short in range(2**o-1):\n",
    "                    omega_short = transform_j_to_omega(j_short,o)\n",
    "                    omega_subset = 0*omega_subset\n",
    "                    omega_subset[np.nonzero(omega)] = omega_short\n",
    "                    j_subset = transform_omega_to_j(omega_subset,d)\n",
    "\n",
    "                    f_hat_omega[j_omega] -= f_hat_omega[j_subset]\n",
    "  \n",
    "        \n",
    "    ''' Estimate eta '''\n",
    "    eta_test = 1/2\n",
    "    for o in range(d+1):\n",
    "        l_max = len(obs_patterns_with_o_observations_and_length_d[d][o])\n",
    "        for omega_d_o in range(l_max):\n",
    "            \n",
    "            # get observation pattern, transform to index\n",
    "            omega = obs_patterns_with_o_observations_and_length_d[d][o][omega_d_o]\n",
    "            j_omega = transform_omega_to_j(omega,d)\n",
    "            \n",
    "            # check if omega<= element for some element in Omega_hat, return 1 if this is the case\n",
    "            helpy = 0 \n",
    "            for elem in Omega_hat:\n",
    "                if (omega<=elem).all():\n",
    "                    helpy = 1\n",
    "                    \n",
    "            # if intersection is empty, add omega to Omega_hat\n",
    "            if helpy == 1:\n",
    "                eta_test += f_hat_omega[j_omega]\n",
    "                            \n",
    "    if eta_test<1/2:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a390711b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T20:49:52.578713Z",
     "iopub.status.busy": "2023-05-17T20:49:52.578081Z",
     "iopub.status.idle": "2023-05-17T20:49:52.580001Z",
     "shell.execute_reply": "2023-05-17T20:49:52.580566Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "HAM Classifier - estimates Omega hat and then uses the oracle version\n",
    "\"\"\"\n",
    "\n",
    "''' Estimate Omega_star using missing data anova decomposition '''\n",
    "def estimate_Omega_star(X_train, Y_train, O_train):\n",
    "    \n",
    "    # Quantities needed for thresholding\n",
    "    tau_omega = np.ones(2**d)\n",
    "    sigma_hat_omega_sq = np.zeros(2**d)\n",
    "    \n",
    "    # f_0 is the expectation of Y-1/2\n",
    "    f_hat_0 = sum(Y_train)/len(Y_train) - 1/2\n",
    "    sigma_hat_omega_sq[0] = f_hat_0**2\n",
    "    \n",
    "    \"\"\" Estimate f_omega at all training points for each observation pattern \"\"\"   \n",
    "    f_hat_omega = np.zeros((N_train,2**d))\n",
    "    f_hat_omega[:,0] = f_hat_0*np.ones(N_train) \n",
    "    \n",
    "    ''' Iterate through the different observation patterns '''\n",
    "    for o in range(1,d+1):\n",
    "        l_max = len(obs_patterns_with_o_observations_and_length_d[d][o])\n",
    "        for omega_d_o in range(l_max):\n",
    "            \n",
    "            # get observation pattern, transform to index\n",
    "            omega = obs_patterns_with_o_observations_and_length_d[d][o][omega_d_o]\n",
    "            j_omega = transform_omega_to_j(omega,d)\n",
    "            \n",
    "            # calculate number of available cases\n",
    "            N_available = 0\n",
    "            for it in range(N_train):\n",
    "                if (omega<=O_train[it,:]).all():\n",
    "                    N_available += 1\n",
    "            \n",
    "            # calculate \n",
    "            if N_available>0:\n",
    "                gamma_omega = 1#np.amax(gamma*omega)\n",
    "                exponent = beta*gamma_omega/(gamma_omega*(2*beta+sum(omega))+alpha*beta)\n",
    "                k_omega = 1+int(np.floor(N_available**(2*exponent)))\n",
    "                tau_omega[j_omega] = 1/(N_available**exponent)/16\n",
    "            \n",
    "            # For all training points that are available cases for the observation pattern\n",
    "            for it in range(N_train):\n",
    "                if (omega<=O_train[it,:]).all() and N_available>=1:\n",
    "            \n",
    "                    # compute distances to all other training points, only considering the w-observed variables\n",
    "                    distances = []\n",
    "                    for i in range(N_train):\n",
    "                        if (omega<=O_train[i,:]).all():\n",
    "                            dist = 0\n",
    "                            for k in range(d):\n",
    "                                if omega[k]==1:\n",
    "                                    dist += (X_train[it,k]-X_train[i,k])**2\n",
    "                            distances.append(np.sqrt(dist))\n",
    "                        else:\n",
    "                            distances.append(1000) # make sure that unavailable data points are not a nearest neighbour\n",
    "\n",
    "                    # sort distances and decide on k_omega and the threshold tau_omega\n",
    "                    sort_index = np.argsort(distances)\n",
    "\n",
    "                    # add Monte Carlo estimate of eta to f_omega\n",
    "                    for i in range(k_omega):\n",
    "                        f_hat_omega[it,j_omega] += 1/k_omega * Y_train[sort_index[i]] \n",
    "\n",
    "                    # substract 1/2 from the estimate\n",
    "                    f_hat_omega[it,j_omega] -= 1/2\n",
    "\n",
    "                    # substract Monte Carlo estimates of f_{omega_subset} from f_omega\n",
    "                    omega_subset = np.zeros(d,dtype=\"int\")\n",
    "                    for j_short in range(2**o-1):\n",
    "                        omega_short = transform_j_to_omega(j_short,o)\n",
    "                        omega_subset = 0*omega_subset\n",
    "                        omega_subset[np.nonzero(omega)] = omega_short\n",
    "                        j_subset = transform_omega_to_j(omega_subset,d)\n",
    "\n",
    "                        f_hat_omega[it,j_omega] -= f_hat_omega[it,j_subset]\n",
    "                    \n",
    "            # Calculate Sobol index                   \n",
    "            if N_available>=1:\n",
    "                sigma_hat_omega_sq[j_omega] = 1/N_available * np.sum(f_hat_omega[0:N_train,j_omega]**2)     \n",
    "\n",
    "    \"\"\" Estimate Omega_hat \"\"\"                        \n",
    "    Omega_hat = []\n",
    "    Omega_hat_cup_L_Omega_hat = []\n",
    "    \n",
    "    ''' Iterate through the different observation patterns, starting from the fully observed one '''\n",
    "    for d_prime in range(d+1):\n",
    "        \n",
    "        l_max = len(obs_patterns_with_o_observations_and_length_d[d][d-d_prime])\n",
    "        for omega_d_d_prime in range(l_max):\n",
    "            \n",
    "            # get observation pattern, transform to index\n",
    "            omega = obs_patterns_with_o_observations_and_length_d[d][d-d_prime][omega_d_d_prime]\n",
    "            \n",
    "            # check if U({omega}) intersect hat_Omega is empty, return 0 if this is the case\n",
    "            helpy = 0 \n",
    "            for elem in Omega_hat_cup_L_Omega_hat:\n",
    "                if (elem==omega).all():\n",
    "                    helpy = 1\n",
    "                    \n",
    "            # if intersection is empty, add omega to Omega_hat and L(omega) to Omega_hat_cup_L_Omega_hat\n",
    "            if helpy == 0:\n",
    "                j_omega = transform_omega_to_j(omega,d)\n",
    "                if sigma_hat_omega_sq[j_omega] >= tau_omega[j_omega]:\n",
    "                    Omega_hat.append(omega)\n",
    "                    omega_subset = np.zeros(d,dtype=\"int\")\n",
    "                    for j_short in range(2**(d-d_prime)):\n",
    "                        omega_short = transform_j_to_omega(j_short,d-d_prime)\n",
    "                        omega_subset = 0*omega_subset\n",
    "                        omega_subset[np.nonzero(omega)] = omega_short\n",
    "                        Omega_hat_cup_L_Omega_hat.append(omega_subset)\n",
    "        \n",
    "    return Omega_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404be9d6",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dbcf53e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T20:49:52.586790Z",
     "iopub.status.busy": "2023-05-17T20:49:52.586087Z",
     "iopub.status.idle": "2023-05-17T20:49:57.422769Z",
     "shell.execute_reply": "2023-05-17T20:49:57.423199Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayes risk =  0.3666\n"
     ]
    }
   ],
   "source": [
    "''' Set Constants '''\n",
    "iterations = 100 # number of iterations for estimating the empirical test error\n",
    "N_test = 1000\n",
    "\n",
    "d = 4 # dimension of X, number of variables\n",
    "alpha = 1\n",
    "beta = 1\n",
    "gamma = np.ones(d)\n",
    "gamma_max = np.amax(gamma)\n",
    "\n",
    "def eta(x):\n",
    "    return 1/2 + (x[2]-1/2)*(x[1]**2)/2 + (x[3]-1/2)/2\n",
    "\n",
    "Bayes_risk = 0\n",
    "for _ in range(1000000):\n",
    "    eta_point = eta(np.random.uniform(size=d))\n",
    "    Bayes_risk += min(eta_point,1-eta_point)\n",
    "Bayes_risk = Bayes_risk/1000000\n",
    "print('Bayes risk = ', np.round(Bayes_risk,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "195420c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-17T20:49:57.524475Z",
     "iopub.status.busy": "2023-05-17T20:49:57.477370Z",
     "iopub.status.idle": "2023-05-18T02:07:48.242312Z",
     "shell.execute_reply": "2023-05-18T02:07:48.242848Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime Complete Case kNN (in s):  22.058\n",
      "    Accuracy:  0.55\n",
      "Runtime Oracle HAM (in s):  245.911\n",
      "    Accuracy:  0.58\n",
      "Runtime HAM (in s):  422.319\n",
      "    Accuracy:  0.592\n",
      "\n",
      "Estimated runtime (in min):  1150.481\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a3f9937f5625>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;31m# Oracle HAM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mHAM_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOmega_star\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mO_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m             \u001b[0maccuracy_oracle_HAM\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mN_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-560c869b17f6>\u001b[0m in \u001b[0;36mHAM_classifier\u001b[0;34m(x_test, Omega_hat, X_train, Y_train, O_train)\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0momega\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0mO_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m                         \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/MissData/lib/python3.9/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_all\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m# Parsing keyword arguments is currently fairly slow, so avoid it for now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mumr_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "EXAMPLE 2 - no missingness\n",
    "'''\n",
    "\n",
    "N_train = 1000 \n",
    "\n",
    "\n",
    "''' \n",
    "Create 1 training and test point set, show runtime and calculate expected run time for simulation \n",
    "'''\n",
    "# Generate Training Data \n",
    "X_train = np.random.uniform(size=(N_train,d))  \n",
    "Y_train = np.zeros(N_train)\n",
    "O_train = np.ones((N_train,d))\n",
    "for i in range(N_train):\n",
    "    Y_train[i] = np.random.random() < eta(X_train[i,:])  \n",
    "\n",
    "# Generate Test Points\n",
    "x_test = np.random.uniform(size=(N_test,d))  \n",
    "y_test = np.zeros(N_test)\n",
    "for i in range(N_test):\n",
    "    y_test[i] = np.random.random() < eta(x_test[i,:]) \n",
    "    \n",
    "\n",
    "# Complete Case kNN\n",
    "start = time.time()\n",
    "accuracy_cc_kNN = 0\n",
    "for i in range(N_test):\n",
    "    if y_test[i] == complete_case_kNN_classifier(x_test[i,:],X_train,Y_train,O_train):\n",
    "        accuracy_cc_kNN += 1/N_test\n",
    "end = time.time()\n",
    "run_time_cc_kNN = end-start\n",
    "print('Runtime Complete Case kNN (in s): ',np.round(run_time_cc_kNN,3))\n",
    "print('    Accuracy: ',np.round(accuracy_cc_kNN,3))\n",
    "\n",
    "# Oracle HAM\n",
    "start = time.time()\n",
    "Omega_star = []\n",
    "Omega_star.append(np.array([0,1,1,0],dtype=\"int\"))\n",
    "Omega_star.append(np.array([0,0,0,1],dtype=\"int\"))\n",
    "accuracy_oracle_HAM = 0\n",
    "for i in range(N_test):\n",
    "    if y_test[i] == HAM_classifier(x_test[i,:], Omega_star, X_train, Y_train, O_train):\n",
    "        accuracy_oracle_HAM += 1/N_test\n",
    "end = time.time()\n",
    "run_time_oracle_HAM = end-start\n",
    "print('Runtime Oracle HAM (in s): ',np.round(run_time_oracle_HAM,3))\n",
    "print('    Accuracy: ',np.round(accuracy_oracle_HAM,3))\n",
    "\n",
    "# Adaptive HAM\n",
    "start = time.time()\n",
    "Omega_hat = []\n",
    "Omega_hat = estimate_Omega_star(X_train, Y_train, O_train)\n",
    "accuracy_HAM = 0\n",
    "for i in range(N_test):\n",
    "    if y_test[i] == HAM_classifier(x_test[i,:], Omega_hat, X_train, Y_train, O_train):\n",
    "        accuracy_HAM += 1/N_test\n",
    "end = time.time()\n",
    "run_time_HAM = end-start\n",
    "print('Runtime HAM (in s): ',np.round(run_time_HAM,3))\n",
    "print('    Accuracy: ',np.round(accuracy_HAM,3))\n",
    "\n",
    "\n",
    "print('\\nEstimated runtime (in min): ',np.round(iterations*(run_time_cc_kNN+run_time_HAM+run_time_oracle_HAM)/60,3))\n",
    "\n",
    "\n",
    "''' \n",
    "Create training and test point sets, estimate empirical test error\n",
    "'''\n",
    "accuracy_cc_kNN = np.zeros(iterations)\n",
    "accuracy_oracle_HAM = np.zeros(iterations)\n",
    "accuracy_HAM = np.zeros(iterations)\n",
    "\n",
    "for it in range(iterations):\n",
    "    \n",
    "    # Generate Training Data \n",
    "    X_train = np.random.uniform(size=(N_train,d))  \n",
    "    Y_train = np.zeros(N_train)\n",
    "    O_train = np.ones((N_train,d))\n",
    "    for i in range(N_train):\n",
    "        Y_train[i] = np.random.random() < eta(X_train[i,:])  \n",
    "\n",
    "    # Generate Test Points\n",
    "    x_test = np.random.uniform(size=(N_test,d))  \n",
    "    y_test = np.zeros(N_test)\n",
    "    for i in range(N_test):\n",
    "        y_test[i] = np.random.random() < eta(x_test[i,:]) \n",
    "        \n",
    "    ''' Estimate Test Errors ''' \n",
    "    # Complete Case kNN\n",
    "    for i in range(N_test):\n",
    "        if y_test[i] == complete_case_kNN_classifier(x_test[i,:],X_train,Y_train,O_train):\n",
    "            accuracy_cc_kNN[it] += 1/N_test\n",
    "\n",
    "    # Oracle HAM\n",
    "    for i in range(N_test):\n",
    "        if y_test[i] == HAM_classifier(x_test[i,:], Omega_star, X_train, Y_train, O_train):\n",
    "            accuracy_oracle_HAM[it] += 1/N_test\n",
    "\n",
    "    # HAM\n",
    "    Omega_hat = []\n",
    "    Omega_hat = estimate_Omega_star(X_train, Y_train, O_train)\n",
    "    for i in range(N_test):\n",
    "        if y_test[i] == HAM_classifier(x_test[i,:], Omega_hat, X_train, Y_train, O_train):\n",
    "            accuracy_HAM[it] += 1/N_test\n",
    "            \n",
    "    \n",
    "print('\\n\\nTest Accuracy Complete Case kNN: ',np.round(np.sum(accuracy_cc_kNN)/iterations,4))\n",
    "print('Test Accuracy Oracle HAM: ',np.round(np.sum(accuracy_oracle_HAM)/iterations,4))\n",
    "print('Test Accuracy HAM: ',np.round(np.sum(accuracy_HAM)/iterations,4))\n",
    "\n",
    "summary_accuracies = [accuracy_cc_kNN,accuracy_oracle_HAM,accuracy_HAM]\n",
    "summary_plot = sns.violinplot(summary_accuracies)\n",
    "\n",
    "summary_plot.set_xticklabels(['CC','oracle HAM','HAM'])\n",
    "\n",
    "plt.show(summary_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ed9708",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-18T02:07:48.247005Z",
     "iopub.status.busy": "2023-05-18T02:07:48.246404Z",
     "iopub.status.idle": "2023-05-18T02:07:48.251425Z",
     "shell.execute_reply": "2023-05-18T02:07:48.251853Z"
    }
   },
   "outputs": [],
   "source": [
    "''' Save accuracies for further use '''\n",
    "\n",
    "np.save('Ex2_no_missingness_all_accuracies_cc_kNN',accuracy_cc_kNN[0:100])\n",
    "np.save('Ex2_no_missingness_all_accuracies_oracle_HAM',accuracy_oracle_HAM[0:100])\n",
    "np.save('Ex2_no_missingness_all_accuracies_HAM',accuracy_HAM[0:100])\n",
    "np.save('Ex2_no_missingness_Bayes_risk',Bayes_risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c11d57c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
